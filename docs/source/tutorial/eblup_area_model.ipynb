{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area level model: empirical best linear unbiased predictor (EBLUP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small area estimation (SAE) are useful techniques when the sample sizes are not sufficient to provide reliable direct domain estimates given the sampling design. In this tutorial, the direct estimates refer to estimates obtained from the design-based approach. It usually consists of applying adjusted design weights to the variable of interest to compute sample parameters as estimates of equivalent population parameters. When auxiliary information is available, we can use model assisted survey methods can be used to estimate population parameters. \n",
    "\n",
    "In this tutorial, we will go futher and use modeling techniques to produce domains estimates. For the area level model, the modeling is done at the area level using generalized linear mixed models. The sections below shows how to use the *EblupAreaModel* class from the *samplics* package to produce area level estimates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milk Expenditure data\n",
    "\n",
    "To illustrate the EblupAreaModel class, we will use the Milk Expenditure dataset used in Rao and Molina (2015). As mentioned in the book, this dataset was originally used by Arora and Lahiri (1997) and later by You and Chapman (2006). For the R users, this dataset is also used by the R package sae (https://cran.r-project.org/web/packages/sae/index.html). \n",
    "\n",
    "The Milk Expenditure data contains 43 observations on the average expenditure on fresh milk for the year 1989. The datasets has the following values: major area representing (major_area), small area (small_area), sample size (samp_size), direct survey estimates of average expenditure (direct_est), standard error of the direct estimate (std_error), and coefficient of variation of the direct estimates (coef_variance). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from samplics.datasets import load_expenditure_milk\n",
    "from samplics.sae import EblupAreaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 15 observations of the Milk Expendure dataset\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>major_area</th>\n",
       "      <th>small_area</th>\n",
       "      <th>samp_size</th>\n",
       "      <th>direct_est</th>\n",
       "      <th>std_error</th>\n",
       "      <th>coef_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>238</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>207</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>165</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>153</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>210</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>383</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>255</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>226</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>224</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>212</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>211</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>179</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>312</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>241</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>205</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    major_area  small_area  samp_size  direct_est  std_error  coef_var\n",
       "28           4          29        238       0.796      0.106     0.133\n",
       "29           4          30        207       0.565      0.089     0.158\n",
       "30           4          31        165       0.886      0.225     0.254\n",
       "31           4          32        153       0.952      0.205     0.215\n",
       "32           4          33        210       0.807      0.119     0.147\n",
       "33           4          34        383       0.582      0.067     0.115\n",
       "34           4          35        255       0.684      0.106     0.155\n",
       "35           4          36        226       0.787      0.126     0.160\n",
       "36           4          37        224       0.440      0.092     0.209\n",
       "37           4          38        212       0.759      0.132     0.174\n",
       "38           4          39        211       0.770      0.100     0.130\n",
       "39           4          40        179       0.800      0.113     0.141\n",
       "40           4          41        312       0.756      0.083     0.110\n",
       "41           4          42        241       0.865      0.121     0.140\n",
       "42           4          43        205       0.640      0.129     0.202"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Expenditure on Milk sample data\n",
    "milk_exp_dict = load_expenditure_milk()\n",
    "milk_exp = milk_exp_dict[\"data\"]\n",
    "\n",
    "nb_obs = 15\n",
    "print(f\"\\nFirst {nb_obs} observations of the Milk Expendure dataset\\n\")\n",
    "milk_exp.tail(nb_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBLUP Predictor\n",
    "\n",
    "As shown in the milk expenditure datasets, some of the coefficients of variation are not small which indicates unstability of the direct survey estimates. Hence, we can try to reduce the variability of the estimates by smoothing them through modeling. For illustration purpose, we will model the average expenditure on milk using the major areas as auxiliary variables.\n",
    "\n",
    "First, we use the method *fit()* to estimate the model parameters. The pandas's method *get_dummies()* create a matrix with dummy values (0 and 1) from the categorical variable *major_area*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The estimated fixed effects are: [ 0.96818899  0.13278031  0.22694622 -0.24130104]\n",
      "\n",
      "The estimated standard error of the area random effects is: 0.13619961509121203\n",
      "\n",
      "The convergence statistics are: {'achieved': True, 'iterations': 7, 'precision': 4.849039725307591e-09}\n",
      "\n",
      "The goodness of fit statistics are: {'loglike': -9.40347441551394, 'AIC': 30.80694883102788, 'BIC': 41.37414952518925}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "area = milk_exp[\"small_area\"]\n",
    "yhat = milk_exp[\"direct_est\"]\n",
    "\n",
    "import pandas as pd\n",
    "X = pd.get_dummies(milk_exp[\"major_area\"],drop_first=True)\n",
    "sigma_e = milk_exp[\"std_error\"]\n",
    "\n",
    "## REML method\n",
    "fh_model_reml = EblupAreaModel(method=\"REML\")\n",
    "fh_model_reml.fit(\n",
    "    yhat=yhat, X=X, area=area, error_std=sigma_e, intercept=True, tol=1e-8,\n",
    ")\n",
    "\n",
    "print(f\"\\nThe estimated fixed effects are: {fh_model_reml.fixed_effects}\")\n",
    "print(f\"\\nThe estimated standard error of the area random effects is: {fh_model_reml.re_std}\")\n",
    "print(f\"\\nThe convergence statistics are: {fh_model_reml.convergence}\")\n",
    "print(f\"\\nThe goodness of fit statistics are: {fh_model_reml.goodness}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the the model has been fitted, we can obtain the EBLUP average expenditure on milk by running *predict()* which is a method of *EblupAreaModel* class. This run will produce two main attributes that is *area_est* and *area_mse* which are python dictionaries pairing the small areas to the eblup estimates and the MSE estimates, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1.0219705448470247,\n",
      " 2: 1.0476019518832929,\n",
      " 3: 1.067951426885093,\n",
      " 4: 0.7608165634163992,\n",
      " 5: 0.8461570426977258,\n",
      " 6: 0.9743727062092635,\n",
      " 7: 1.0584526732855335,\n",
      " 8: 1.0977762564423161,\n",
      " 9: 1.2215454913423587,\n",
      " 10: 1.1951460164712608,\n",
      " 11: 0.7852149170863969,\n",
      " 12: 1.2139462074222365,\n",
      " 13: 1.2096597223605197,\n",
      " 14: 0.9834964402356499,\n",
      " 15: 1.1864247095350073,\n",
      " 16: 1.1556981135233566,\n",
      " 17: 1.2263412510186886,\n",
      " 18: 1.2856489898727401,\n",
      " 19: 1.2363248413266212,\n",
      " 20: 1.2349601399238845,\n",
      " 21: 1.0903016265233827,\n",
      " 22: 1.1923057228469667,\n",
      " 23: 1.1216467660137068,\n",
      " 24: 1.2230297222963098,\n",
      " 25: 1.1938054444127764,\n",
      " 26: 0.762719590055247,\n",
      " 27: 0.7649551536523853,\n",
      " 28: 0.733844388348909,\n",
      " 29: 0.769929554574362,\n",
      " 30: 0.6134416227081896,\n",
      " 31: 0.7695560730689718,\n",
      " 32: 0.7958253128224164,\n",
      " 33: 0.7723188482183627,\n",
      " 34: 0.6102300678743072,\n",
      " 35: 0.7001781895145349,\n",
      " 36: 0.7592788108093524,\n",
      " 37: 0.5298863352267293,\n",
      " 38: 0.7434466782997067,\n",
      " 39: 0.7548996333852697,\n",
      " 40: 0.770191966164431,\n",
      " 41: 0.748116424018986,\n",
      " 42: 0.8040775166023042,\n",
      " 43: 0.681086884699362}\n"
     ]
    }
   ],
   "source": [
    "fh_model_reml.predict(\n",
    "    X=X, area=area, intercept=True\n",
    ")\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(fh_model_reml.area_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the utility method *to_dataframe()* to output the estimates as a pandas dataframe. The function provides the area, the estimate and its MSE estimates. We can use *col_names* to customize the name of the columns. For example, using `col_names = [\"small_area\", \"eblup_estimate\", \"eblup_mse\"]`. Otherwise, if col_names is not provided, \"_area\", \"_estimates\" and \"_mse\" are used as defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataframe version of the area level estimates:\n",
      "\n",
      "    parameter  small_area  eblup_estimate  eblup_mse\n",
      "0       mean           1        1.021971   0.013460\n",
      "1       mean           2        1.047602   0.005373\n",
      "2       mean           3        1.067951   0.005702\n",
      "3       mean           4        0.760817   0.008542\n",
      "4       mean           5        0.846157   0.009580\n",
      "5       mean           6        0.974373   0.011671\n",
      "6       mean           7        1.058453   0.015926\n",
      "7       mean           8        1.097776   0.010587\n",
      "8       mean           9        1.221545   0.014184\n",
      "9       mean          10        1.195146   0.014902\n",
      "10      mean          11        0.785215   0.007694\n",
      "11      mean          12        1.213946   0.016337\n",
      "12      mean          13        1.209660   0.012563\n",
      "13      mean          14        0.983496   0.012117\n",
      "14      mean          15        1.186425   0.012031\n",
      "15      mean          16        1.155698   0.011709\n",
      "16      mean          17        1.226341   0.010860\n",
      "17      mean          18        1.285649   0.013691\n",
      "18      mean          19        1.236325   0.011035\n",
      "19      mean          20        1.234960   0.013080\n",
      "20      mean          21        1.090302   0.009949\n",
      "21      mean          22        1.192306   0.017244\n",
      "22      mean          23        1.121647   0.011292\n",
      "23      mean          24        1.223030   0.013625\n",
      "24      mean          25        1.193805   0.008066\n",
      "25      mean          26        0.762720   0.009205\n",
      "26      mean          27        0.764955   0.009205\n",
      "27      mean          28        0.733844   0.016477\n",
      "28      mean          29        0.769930   0.007801\n",
      "29      mean          30        0.613442   0.006099\n",
      "30      mean          31        0.769556   0.015442\n",
      "31      mean          32        0.795825   0.014658\n",
      "32      mean          33        0.772319   0.009025\n",
      "33      mean          34        0.610230   0.003871\n",
      "34      mean          35        0.700178   0.007801\n",
      "35      mean          36        0.759279   0.009646\n",
      "36      mean          37        0.529886   0.006404\n",
      "37      mean          38        0.743447   0.010156\n",
      "38      mean          39        0.754900   0.007210\n",
      "39      mean          40        0.770192   0.008470\n",
      "40      mean          41        0.748116   0.005485\n",
      "41      mean          42        0.804078   0.009205\n",
      "42      mean          43        0.681087   0.009904\n"
     ]
    }
   ],
   "source": [
    "milk_est_reml = fh_model_reml.to_dataframe(col_names = [\"parameter\", \"small_area\", \"eblup_estimate\", \"eblup_mse\"])\n",
    "print(f\"\\nThe dataframe version of the area level estimates:\\n\\n {milk_est_reml}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also fit the model parameters using the maximum likelihood (ML) method which will impact the MSE estimation as well. To estimate the area means using the ML methdo, we only need to set *method=\"ML\"* then run the prediction as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataframe version of the ML area level estimates:\n",
      "\n",
      "    parameter  small_area  eblup_estimate  eblup_mse\n",
      "0       mean           1        1.016173   0.013580\n",
      "1       mean           2        1.043697   0.005513\n",
      "2       mean           3        1.062817   0.005851\n",
      "3       mean           4        0.775349   0.008735\n",
      "4       mean           5        0.855490   0.009775\n",
      "5       mean           6        0.973586   0.011841\n",
      "6       mean           7        1.047478   0.015934\n",
      "7       mean           8        1.095344   0.010822\n",
      "8       mean           9        1.205409   0.014346\n",
      "9       mean          10        1.181256   0.015036\n",
      "10      mean          11        0.803370   0.007911\n",
      "11      mean          12        1.196775   0.016405\n",
      "12      mean          13        1.196159   0.012771\n",
      "13      mean          14        0.991405   0.012335\n",
      "14      mean          15        1.186883   0.012192\n",
      "15      mean          16        1.159036   0.011877\n",
      "16      mean          17        1.223237   0.011041\n",
      "17      mean          18        1.275519   0.013805\n",
      "18      mean          19        1.232285   0.011214\n",
      "19      mean          20        1.230442   0.013214\n",
      "20      mean          21        1.098577   0.010138\n",
      "21      mean          22        1.192160   0.017194\n",
      "22      mean          23        1.127992   0.011468\n",
      "23      mean          24        1.219628   0.013742\n",
      "24      mean          25        1.193626   0.008251\n",
      "25      mean          26        0.759065   0.009345\n",
      "26      mean          27        0.761123   0.009345\n",
      "27      mean          28        0.731565   0.016390\n",
      "28      mean          29        0.766273   0.007942\n",
      "29      mean          30        0.619145   0.006222\n",
      "30      mean          31        0.762939   0.015404\n",
      "31      mean          32        0.786375   0.014656\n",
      "32      mean          33        0.767978   0.009165\n",
      "33      mean          34        0.614135   0.003947\n",
      "34      mean          35        0.701311   0.007942\n",
      "35      mean          36        0.755756   0.009782\n",
      "36      mean          37        0.540665   0.006532\n",
      "37      mean          38        0.741132   0.010286\n",
      "38      mean          39        0.752451   0.007347\n",
      "39      mean          40        0.766242   0.008613\n",
      "40      mean          41        0.746536   0.005598\n",
      "41      mean          42        0.797140   0.009345\n",
      "42      mean          43        0.684098   0.010037\n"
     ]
    }
   ],
   "source": [
    "## ML method\n",
    "fh_model_ml = EblupAreaModel(method=\"ML\")\n",
    "fh_model_ml.fit(\n",
    "    yhat=yhat, X=X, area=area, error_std=sigma_e, intercept=True, tol=1e-8,\n",
    ")\n",
    "\n",
    "milk_est_ml = fh_model_ml.predict(\n",
    "    X=X, area=area, intercept=True\n",
    ")\n",
    "\n",
    "milk_est_ml = fh_model_ml.to_dataframe(col_names = [\"parameter\", \"small_area\", \"eblup_estimate\", \"eblup_mse\"])\n",
    "\n",
    "\n",
    "print(f\"\\nThe dataframe version of the ML area level estimates:\\n\\n {milk_est_ml}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar, we can use the Fay-Herriot method as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataframe version of the ML area level estimates:\n",
      "\n",
      "    parameter  small_area  eblup_estimate  eblup_mse\n",
      "0       mean           1        1.017976   0.012757\n",
      "1       mean           2        1.044964   0.005314\n",
      "2       mean           3        1.064481   0.005632\n",
      "3       mean           4        0.770692   0.008323\n",
      "4       mean           5        0.852512   0.009284\n",
      "5       mean           6        0.973826   0.011178\n",
      "6       mean           7        1.050857   0.014868\n",
      "7       mean           8        1.096165   0.010253\n",
      "8       mean           9        1.210505   0.013471\n",
      "9       mean          10        1.185640   0.014095\n",
      "10      mean          11        0.797569   0.007558\n",
      "11      mean          12        1.202150   0.015325\n",
      "12      mean          13        1.200459   0.012039\n",
      "13      mean          14        0.988971   0.011640\n",
      "14      mean          15        1.186745   0.011467\n",
      "15      mean          16        1.157992   0.011182\n",
      "16      mean          17        1.224223   0.010424\n",
      "17      mean          18        1.278680   0.012914\n",
      "18      mean          19        1.233566   0.010581\n",
      "19      mean          20        1.231860   0.012386\n",
      "20      mean          21        1.095955   0.009600\n",
      "21      mean          22        1.192213   0.015890\n",
      "22      mean          23        1.125997   0.010811\n",
      "23      mean          24        1.220695   0.012858\n",
      "24      mean          25        1.193687   0.007865\n",
      "25      mean          26        0.760244   0.008855\n",
      "26      mean          27        0.762358   0.008855\n",
      "27      mean          28        0.732288   0.015042\n",
      "28      mean          29        0.767459   0.007569\n",
      "29      mean          30        0.617310   0.005975\n",
      "30      mean          31        0.764997   0.014212\n",
      "31      mean          32        0.789315   0.013572\n",
      "32      mean          33        0.769376   0.008692\n",
      "33      mean          34        0.612861   0.003833\n",
      "34      mean          35        0.700962   0.007569\n",
      "35      mean          36        0.756891   0.009253\n",
      "36      mean          37        0.537193   0.006264\n",
      "37      mean          38        0.741882   0.009709\n",
      "38      mean          39        0.753251   0.007020\n",
      "39      mean          40        0.767519   0.008186\n",
      "40      mean          41        0.747059   0.005391\n",
      "41      mean          42        0.799363   0.008855\n",
      "42      mean          43        0.683161   0.009484\n"
     ]
    }
   ],
   "source": [
    "## FH method\n",
    "fh_model_fh = EblupAreaModel(method=\"FH\")\n",
    "fh_model_fh.fit(\n",
    "    yhat=yhat, X=X, area=area, error_std=sigma_e, intercept=True, tol=1e-8,\n",
    ")\n",
    "\n",
    "milk_est_fh = fh_model_fh.predict(\n",
    "    X=X, area=area, intercept=True\n",
    ")\n",
    "\n",
    "milk_est_fh = fh_model_fh.to_dataframe(col_names = [\"parameter\", \"small_area\", \"eblup_estimate\", \"eblup_mse\"])\n",
    "\n",
    "\n",
    "print(f\"\\nThe dataframe version of the ML area level estimates:\\n\\n {milk_est_fh}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1838300bc832aaa997391910aaeeb5e0ca0a920c679ba2ab90cd483a45827fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('.venv': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
