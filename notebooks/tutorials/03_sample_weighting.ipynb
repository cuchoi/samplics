{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Sample Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tables of Contents\n",
    "\n",
    "- [Objective](#section0)\n",
    "\n",
    "- [Design (base) Weight](#section1)\n",
    "\n",
    "- [Non-Response Adjustment](#section2)\n",
    "\n",
    "- [Post-Stratification](#section3)\n",
    "\n",
    "- [Normalization](#section4)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective <a name=\"section0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import samplics as svm\n",
    "from samplics.weighting import SampleWeight"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Design (base) weight <a name=\"section1\"></a>\n",
    "\n",
    "The design weight is the inverse of the overall probability of selection which is the product of the first and second probability of selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cluster</th>\n      <th>region</th>\n      <th>psu_prob</th>\n      <th>household</th>\n      <th>ssu_prob</th>\n      <th>inclusion_prob</th>\n      <th>design_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>72</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>73</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>75</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>715</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>722</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>724</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>755</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>761</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>764</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>782</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>795</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>7111</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>7112</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>7117</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>7</td>\n      <td>North</td>\n      <td>0.187726</td>\n      <td>7123</td>\n      <td>0.115385</td>\n      <td>0.021661</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n      <td>North</td>\n      <td>0.866426</td>\n      <td>1037</td>\n      <td>0.022727</td>\n      <td>0.019691</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10</td>\n      <td>North</td>\n      <td>0.866426</td>\n      <td>1056</td>\n      <td>0.022727</td>\n      <td>0.019691</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10</td>\n      <td>North</td>\n      <td>0.866426</td>\n      <td>1074</td>\n      <td>0.022727</td>\n      <td>0.019691</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10</td>\n      <td>North</td>\n      <td>0.866426</td>\n      <td>1078</td>\n      <td>0.022727</td>\n      <td>0.019691</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10</td>\n      <td>North</td>\n      <td>0.866426</td>\n      <td>10105</td>\n      <td>0.022727</td>\n      <td>0.019691</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>10</td>\n      <td>North</td>\n      <td>0.866426</td>\n      <td>10209</td>\n      <td>0.022727</td>\n      <td>0.019691</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>10</td>\n      <td>North</td>\n      <td>0.866426</td>\n      <td>10211</td>\n      <td>0.022727</td>\n      <td>0.019691</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>10</td>\n      <td>North</td>\n      <td>0.866426</td>\n      <td>10228</td>\n      <td>0.022727</td>\n      <td>0.019691</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>10</td>\n      <td>North</td>\n      <td>0.866426</td>\n      <td>10266</td>\n      <td>0.022727</td>\n      <td>0.019691</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>10</td>\n      <td>North</td>\n      <td>0.866426</td>\n      <td>10317</td>\n      <td>0.022727</td>\n      <td>0.019691</td>\n      <td>50.783333</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    cluster region  psu_prob  household  ssu_prob  inclusion_prob  \\\n0         7  North  0.187726         72  0.115385        0.021661   \n1         7  North  0.187726         73  0.115385        0.021661   \n2         7  North  0.187726         75  0.115385        0.021661   \n3         7  North  0.187726        715  0.115385        0.021661   \n4         7  North  0.187726        722  0.115385        0.021661   \n5         7  North  0.187726        724  0.115385        0.021661   \n6         7  North  0.187726        755  0.115385        0.021661   \n7         7  North  0.187726        761  0.115385        0.021661   \n8         7  North  0.187726        764  0.115385        0.021661   \n9         7  North  0.187726        782  0.115385        0.021661   \n10        7  North  0.187726        795  0.115385        0.021661   \n11        7  North  0.187726       7111  0.115385        0.021661   \n12        7  North  0.187726       7112  0.115385        0.021661   \n13        7  North  0.187726       7117  0.115385        0.021661   \n14        7  North  0.187726       7123  0.115385        0.021661   \n15       10  North  0.866426       1037  0.022727        0.019691   \n16       10  North  0.866426       1056  0.022727        0.019691   \n17       10  North  0.866426       1074  0.022727        0.019691   \n18       10  North  0.866426       1078  0.022727        0.019691   \n19       10  North  0.866426      10105  0.022727        0.019691   \n20       10  North  0.866426      10209  0.022727        0.019691   \n21       10  North  0.866426      10211  0.022727        0.019691   \n22       10  North  0.866426      10228  0.022727        0.019691   \n23       10  North  0.866426      10266  0.022727        0.019691   \n24       10  North  0.866426      10317  0.022727        0.019691   \n\n    design_weight  \n0       46.166667  \n1       46.166667  \n2       46.166667  \n3       46.166667  \n4       46.166667  \n5       46.166667  \n6       46.166667  \n7       46.166667  \n8       46.166667  \n9       46.166667  \n10      46.166667  \n11      46.166667  \n12      46.166667  \n13      46.166667  \n14      46.166667  \n15      50.783333  \n16      50.783333  \n17      50.783333  \n18      50.783333  \n19      50.783333  \n20      50.783333  \n21      50.783333  \n22      50.783333  \n23      50.783333  \n24      50.783333  "
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psu_sample = pd.read_csv(\"psu_sample.csv\")\n",
    "ssu_sample = pd.read_csv(\"ssu_sample.csv\")\n",
    "\n",
    "full_sample = pd.merge(\n",
    "    psu_sample[[\"cluster\", \"region\", \"psu_prob\"]], \n",
    "    ssu_sample[[\"cluster\", \"household\", \"ssu_prob\"]], \n",
    "    on=\"cluster\")\n",
    "\n",
    "full_sample[\"inclusion_prob\"] = full_sample[\"psu_prob\"] * full_sample[\"ssu_prob\"] \n",
    "full_sample[\"design_weight\"] = 1 / full_sample[\"inclusion_prob\"] \n",
    "\n",
    "full_sample.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To illustrate the class *SampleWeight*, we will simulate non-response status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cluster</th>\n      <th>region</th>\n      <th>design_weight</th>\n      <th>response_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>non-respondent</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>ineligible</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    cluster region  design_weight response_status\n0         7  North      46.166667      ineligible\n1         7  North      46.166667      respondent\n2         7  North      46.166667      respondent\n3         7  North      46.166667      respondent\n4         7  North      46.166667         unknown\n5         7  North      46.166667      respondent\n6         7  North      46.166667      respondent\n7         7  North      46.166667      ineligible\n8         7  North      46.166667      respondent\n9         7  North      46.166667      respondent\n10        7  North      46.166667      respondent\n11        7  North      46.166667  non-respondent\n12        7  North      46.166667      respondent\n13        7  North      46.166667      ineligible\n14        7  North      46.166667      respondent\n15       10  North      50.783333  non-respondent\n16       10  North      50.783333      respondent\n17       10  North      50.783333      respondent\n18       10  North      50.783333  non-respondent\n19       10  North      50.783333      ineligible\n20       10  North      50.783333      respondent\n21       10  North      50.783333         unknown\n22       10  North      50.783333      respondent\n23       10  North      50.783333      respondent\n24       10  North      50.783333  non-respondent"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "full_sample[\"response_status\"] = np.random.choice(\n",
    "    [\"ineligible\",\"respondent\", \"non-respondent\",\"unknown\"], \n",
    "    size=full_sample.shape[0], \n",
    "    p=(0.10, 0.70, 0.15, 0.05)\n",
    "    )\n",
    "\n",
    "full_sample[[\"cluster\", \"region\",\"design_weight\", \"response_status\"]].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-Response Adjustment <a name=\"section2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cluster</th>\n      <th>region</th>\n      <th>design_weight</th>\n      <th>response_status</th>\n      <th>nr_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>unknown</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>ineligible</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>unknown</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    cluster region  design_weight response_status  nr_weight\n0         7  North      46.166667      ineligible  46.166667\n1         7  North      46.166667      respondent  60.236508\n2         7  North      46.166667      respondent  60.236508\n3         7  North      46.166667      respondent  60.236508\n4         7  North      46.166667         unknown   0.000000\n5         7  North      46.166667      respondent  60.236508\n6         7  North      46.166667      respondent  60.236508\n7         7  North      46.166667      ineligible  46.166667\n8         7  North      46.166667      respondent  60.236508\n9         7  North      46.166667      respondent  60.236508\n10        7  North      46.166667      respondent  60.236508\n11        7  North      46.166667  non-respondent   0.000000\n12        7  North      46.166667      respondent  60.236508\n13        7  North      46.166667      ineligible  46.166667\n14        7  North      46.166667      respondent  60.236508\n15       10  North      50.783333  non-respondent   0.000000\n16       10  North      50.783333      respondent  66.260159\n17       10  North      50.783333      respondent  66.260159\n18       10  North      50.783333  non-respondent   0.000000\n19       10  North      50.783333      ineligible  50.783333\n20       10  North      50.783333      respondent  66.260159\n21       10  North      50.783333         unknown   0.000000\n22       10  North      50.783333      respondent  66.260159\n23       10  North      50.783333      respondent  66.260159\n24       10  North      50.783333  non-respondent   0.000000"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_mapping = {\n",
    "    \"in\": \"ineligible\", \"rr\": \"respondent\", \"nr\": \"non-respondent\", \"uk\":\"unknown\"\n",
    "    }\n",
    "\n",
    "full_sample[\"nr_weight\"] = SampleWeight().adjust(\n",
    "    samp_weight=full_sample[\"design_weight\"], \n",
    "    adjust_class=full_sample[\"region\"], \n",
    "    resp_status=full_sample[\"response_status\"], \n",
    "    resp_dict=status_mapping\n",
    "    )\n",
    "\n",
    "full_sample[[\"cluster\", \"region\",\"design_weight\", \"response_status\", \"nr_weight\"]].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Important.** The default call of *adjust()* expects standard codes for response status that is \"in\", \"rr\", \"nr\", and \"uk\" where \"in\" means ineligible, \"rr\" means respondent, \"nr\" means non-respondent, and \"uk\" means unknown eligibility.\n",
    "\n",
    "If we called *adjust()* without the parameter *response_dict*, the run would fail with an assertion error.  The current error message is the following: *The response status must only contains values in ('in', 'rr', 'nr', 'uk') or the mapping should be provided using response_dict parameter*. For the call to run without using *response_dict* it is necessary that the response status takes only codes \"in\", \"rr\", \"nr\", or \"uk\". The variable associated with *response_status* can contain any code but a mapping is necessary when the response variable is not constructed using the standard codes.\n",
    "\n",
    "To further illustrate the mapping of response status, let's assume that we have response_status2 which has the values 100 for ineligible, 200 for non-respondent, 300 for respondent, and 999 for unknown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>response_status</th>\n      <th>ineligible</th>\n      <th>non-respondent</th>\n      <th>respondent</th>\n      <th>unknown</th>\n    </tr>\n    <tr>\n      <th>row_0</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>100</th>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>0</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>0</td>\n      <td>0</td>\n      <td>106</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "response_status  ineligible  non-respondent  respondent  unknown\nrow_0                                                           \n100                      16               0           0        0\n200                       0              23           0        0\n300                       0               0         106        0\n999                       0               0           0        5"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_status2 = np.repeat(100, full_sample[\"response_status\"].shape[0])\n",
    "response_status2[full_sample[\"response_status\"]==\"non-respondent\"] = 200\n",
    "response_status2[full_sample[\"response_status\"]==\"respondent\"] = 300\n",
    "response_status2[full_sample[\"response_status\"]==\"unknown\"] = 999\n",
    "\n",
    "pd.crosstab(response_status2, full_sample[\"response_status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To use *response_status2*, we need to map the values 100, 200, 300 and 999 to \"in\", \"rr\", \"nr\", and \"uk\". This mapping is done below through the python dictionnary *status_mapping2*. Using *status_mapping2* in the function call *adjust()* will to the same adjustment as in the previous run i.e. *nr_weight* and *nr_weight2* contain the same adjsuted weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/msdiallo/Dev/survey-methods/samplics/.venv/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  mask |= (ar1 == a)\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cluster</th>\n      <th>region</th>\n      <th>design_weight</th>\n      <th>response_status</th>\n      <th>nr_weight</th>\n      <th>nr_weight2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n      <td>46.166667</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>unknown</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n      <td>46.166667</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n      <td>46.166667</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>ineligible</td>\n      <td>50.783333</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>unknown</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    cluster region  design_weight response_status  nr_weight  nr_weight2\n0         7  North      46.166667      ineligible  46.166667   46.166667\n1         7  North      46.166667      respondent  60.236508   60.236508\n2         7  North      46.166667      respondent  60.236508   60.236508\n3         7  North      46.166667      respondent  60.236508   60.236508\n4         7  North      46.166667         unknown   0.000000    0.000000\n5         7  North      46.166667      respondent  60.236508   60.236508\n6         7  North      46.166667      respondent  60.236508   60.236508\n7         7  North      46.166667      ineligible  46.166667   46.166667\n8         7  North      46.166667      respondent  60.236508   60.236508\n9         7  North      46.166667      respondent  60.236508   60.236508\n10        7  North      46.166667      respondent  60.236508   60.236508\n11        7  North      46.166667  non-respondent   0.000000    0.000000\n12        7  North      46.166667      respondent  60.236508   60.236508\n13        7  North      46.166667      ineligible  46.166667   46.166667\n14        7  North      46.166667      respondent  60.236508   60.236508\n15       10  North      50.783333  non-respondent   0.000000    0.000000\n16       10  North      50.783333      respondent  66.260159   66.260159\n17       10  North      50.783333      respondent  66.260159   66.260159\n18       10  North      50.783333  non-respondent   0.000000    0.000000\n19       10  North      50.783333      ineligible  50.783333   50.783333\n20       10  North      50.783333      respondent  66.260159   66.260159\n21       10  North      50.783333         unknown   0.000000    0.000000\n22       10  North      50.783333      respondent  66.260159   66.260159\n23       10  North      50.783333      respondent  66.260159   66.260159\n24       10  North      50.783333  non-respondent   0.000000    0.000000"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_mapping2 = {\"in\": 100, \"nr\": 200, \"rr\": 300, \"uk\": 999}\n",
    "\n",
    "full_sample[\"nr_weight2\"] = SampleWeight().adjust(\n",
    "    samp_weight=full_sample[\"design_weight\"], \n",
    "    adjust_class=full_sample[\"region\"], \n",
    "    resp_status=response_status2, \n",
    "    resp_dict=status_mapping2\n",
    "    )\n",
    "\n",
    "full_sample[[\"cluster\", \"region\",\"design_weight\", \"response_status\", \"nr_weight\", \"nr_weight2\"]].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If the response status variable only takes values \"in\", \"nr\", \"rr\" and \"uk\" then it is not necessary to provide the mapping dictionary to the function i.e. resp_dict can be ommited from the function call *adjust()*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cluster</th>\n      <th>region</th>\n      <th>design_weight</th>\n      <th>response_status</th>\n      <th>nr_weight</th>\n      <th>nr_weight2</th>\n      <th>nr_weight3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n      <td>46.166667</td>\n      <td>46.166667</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>unknown</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n      <td>46.166667</td>\n      <td>46.166667</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>ineligible</td>\n      <td>46.166667</td>\n      <td>46.166667</td>\n      <td>46.166667</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>7</td>\n      <td>North</td>\n      <td>46.166667</td>\n      <td>respondent</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n      <td>60.236508</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>ineligible</td>\n      <td>50.783333</td>\n      <td>50.783333</td>\n      <td>50.783333</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>unknown</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>respondent</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n      <td>66.260159</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>10</td>\n      <td>North</td>\n      <td>50.783333</td>\n      <td>non-respondent</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    cluster region  design_weight response_status  nr_weight  nr_weight2  \\\n0         7  North      46.166667      ineligible  46.166667   46.166667   \n1         7  North      46.166667      respondent  60.236508   60.236508   \n2         7  North      46.166667      respondent  60.236508   60.236508   \n3         7  North      46.166667      respondent  60.236508   60.236508   \n4         7  North      46.166667         unknown   0.000000    0.000000   \n5         7  North      46.166667      respondent  60.236508   60.236508   \n6         7  North      46.166667      respondent  60.236508   60.236508   \n7         7  North      46.166667      ineligible  46.166667   46.166667   \n8         7  North      46.166667      respondent  60.236508   60.236508   \n9         7  North      46.166667      respondent  60.236508   60.236508   \n10        7  North      46.166667      respondent  60.236508   60.236508   \n11        7  North      46.166667  non-respondent   0.000000    0.000000   \n12        7  North      46.166667      respondent  60.236508   60.236508   \n13        7  North      46.166667      ineligible  46.166667   46.166667   \n14        7  North      46.166667      respondent  60.236508   60.236508   \n15       10  North      50.783333  non-respondent   0.000000    0.000000   \n16       10  North      50.783333      respondent  66.260159   66.260159   \n17       10  North      50.783333      respondent  66.260159   66.260159   \n18       10  North      50.783333  non-respondent   0.000000    0.000000   \n19       10  North      50.783333      ineligible  50.783333   50.783333   \n20       10  North      50.783333      respondent  66.260159   66.260159   \n21       10  North      50.783333         unknown   0.000000    0.000000   \n22       10  North      50.783333      respondent  66.260159   66.260159   \n23       10  North      50.783333      respondent  66.260159   66.260159   \n24       10  North      50.783333  non-respondent   0.000000    0.000000   \n\n    nr_weight3  \n0    46.166667  \n1    60.236508  \n2    60.236508  \n3    60.236508  \n4     0.000000  \n5    60.236508  \n6    60.236508  \n7    46.166667  \n8    60.236508  \n9    60.236508  \n10   60.236508  \n11    0.000000  \n12   60.236508  \n13   46.166667  \n14   60.236508  \n15    0.000000  \n16   66.260159  \n17   66.260159  \n18    0.000000  \n19   50.783333  \n20   66.260159  \n21    0.000000  \n22   66.260159  \n23   66.260159  \n24    0.000000  "
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_status3 = np.repeat(\"in\", full_sample[\"response_status\"].shape[0])\n",
    "response_status3[full_sample[\"response_status\"]==\"non-respondent\"] = \"nr\"\n",
    "response_status3[full_sample[\"response_status\"]==\"respondent\"] = \"rr\"\n",
    "response_status3[full_sample[\"response_status\"]==\"unknown\"] = \"uk\"\n",
    "\n",
    "full_sample[\"nr_weight3\"] = SampleWeight().adjust(\n",
    "    samp_weight=full_sample[\"design_weight\"], \n",
    "    adjust_class=full_sample[\"region\"], \n",
    "    resp_status=response_status3\n",
    "    )\n",
    "\n",
    "full_sample[[\"cluster\", \"region\",\"design_weight\", \"response_status\", \"nr_weight\", \"nr_weight2\", \"nr_weight3\"]].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Post-Stratification <a name=\"section3\"></a>\n",
    "\n",
    "Poststratification is useful to compensate for underepresentation of the sample or to correct for nonsampling error. The most common poststratification method consists of adjusting the sample weights to ensure that they sum to some \"known\" control values by poststratification classes (domains). "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's us that we have very reliable external source e.g. a recent census that provides the number of households by region. The external source has the following control data: 3700 households for East, 1500 for North, 2800 for South and 6500 for West. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just dropping a couple of variables not needed for the rest of the tutorial\n",
    "full_sample.drop(columns=[\"psu_prob\", \"ssu_prob\", \"inclusion_prob\", \"nr_weight2\", \"nr_weight3\"], inplace=True)\n",
    "\n",
    "census_households = {\"East\":3700, \"North\": 1500, \"South\": 2800, \"West\":6500}\n",
    "\n",
    "full_sample[\"ps_weight\"] = SampleWeight().poststratify(\n",
    "    samp_weight=full_sample[\"nr_weight\"], control=census_households, domain=full_sample[\"region\"]\n",
    "    )\n",
    "\n",
    "full_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_weights = full_sample[[\"region\", \"nr_weight\", \"ps_weight\"]].groupby(\"region\").sum()\n",
    "sum_of_weights.reset_index(inplace=True)\n",
    "sum_of_weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sample[\"ps_adjust_fct\"] = round(full_sample[\"ps_weight\"] / full_sample[\"nr_weight\"], 12)\n",
    "\n",
    "pd.crosstab(full_sample[\"ps_adjust_fct\"] , full_sample[\"region\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_ratios = {\"East\":0.25, \"North\": 0.10, \"South\": 0.20, \"West\":0.45}\n",
    "full_sample[\"ps_weight2\"] = SampleWeight().poststratify(\n",
    "    samp_weight=full_sample[\"nr_weight\"], factor=known_ratios, domain=full_sample[\"region\"]\n",
    "    )\n",
    "\n",
    "full_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_weights2 = full_sample[[\"region\", \"nr_weight\", \"ps_weight2\"]].groupby(\"region\").sum()\n",
    "sum_of_weights2.reset_index(inplace=True)\n",
    "sum_of_weights2[\"ratio\"] = sum_of_weights2[\"ps_weight2\"] / sum(sum_of_weights2[\"ps_weight2\"])\n",
    "sum_of_weights2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Obviously, poststratification classes can be formed using variables beyond the ones involved in the sampling design. For exemple, socio-economique variables such as age group, gender, race and education are often used to form poststratification classes/cells."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calibration \n",
    "\n",
    "Calibration is a more general concept for adjusting sample weights to sum to known constants. In this tutorial, we consider the generalized regression (GREG) class of calibration. Assume that we have $\\hat{\\mathbf{Y}} = \\sum_{i \\in s} w_i y_i$ and know population totals $\\mathbf{X} = (\\mathbf{X}_1, ..., \\mathbf{X}_p)^T$ are available. Working under the model $Y_i | \\mathbf{x}_i = \\mathbf{x}^T_i \\mathbf{\\beta} + \\epsilon_i$, the GREG estimator of the population total is \n",
    "\n",
    "$$\\hat{\\mathbf{Y}}_{GR} = \\hat{\\mathbf{Y}} + (\\mathbf{X} - \\hat{\\mathbf{X}})^T\\hat{\\mathbf{B}}$$\n",
    "\n",
    "where $\\hat{\\mathbf{B}}$ is the weighted least squares estimate of $\\mathbf{\\beta}$ and $\\hat{\\mathbf{X}}$ is the survey estimate of $\\mathbf{X}$.\n",
    "\n",
    "The essential of the GREG approach is, under the regression model, to find the adjusted weights $w^{*}_i$ that are the closest to $w_i$, to minimize $h(z) = \\frac{\\sum_{i \\in s} c_i(w_i - z_i)}{w_i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let us simulation three auxiliary variables that is education, poverty and under_five (number of children under five in the household) and assume that we have the following control totals\n",
    "* Total number of under five children: 6300 in the East, 4000 in the North, 6500 in the South and 14000 in the West. \n",
    "* Poverty (Yes: in poverty / No: not in poverty)\n",
    "\n",
    "    | Region &nbsp;| Poverty &nbsp;| Number of households |\n",
    "    |:--------|:--------:|:--------------------:|\n",
    "    | East    |    No    |       2600           |\n",
    "    |         |    Yes   |       1200           |\n",
    "    | North   |    No    |       1500           |\n",
    "    |         |    Yes   |        200           |\n",
    "    | South   |    No    |       1800           |\n",
    "    |         |    Yes   |       1100           |\n",
    "    | West    |    No    |       4500           |\n",
    "    |         |    Yes   |       2200           |\n",
    "\n",
    "* Education (Low: less than secondary, Medium: secondary completed, and High: More than secondary)\n",
    "\n",
    "    | Region &nbsp;| Education &nbsp;| Number of households |\n",
    "    |:--------|:--------:|:------:|\n",
    "    | East    | Low      | 2000   |\n",
    "    |         | Medium   | 1400   |\n",
    "    |         | High     |  350   |\n",
    "    | North   | Low      |  550   |\n",
    "    |         | Medium   |  700   |\n",
    "    |         | High     |  250   |\n",
    "    | South   | Low      | 1300   |\n",
    "    |         | Medium   | 1200   |\n",
    "    |         | High     |  350   |\n",
    "    | West    | Low      | 2100   |\n",
    "    |         | Medium   | 4000   |\n",
    "    |         | High     |  500   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(150)\n",
    "full_sample[\"education\"] = np.random.choice((\"Low\", \"Medium\", \"High\"), size=150, p=(0.40, 0.50, 0.10))\n",
    "full_sample[\"poverty\"] = np.random.choice((0, 1), size=150, p=(0.70, 0.30))\n",
    "full_sample[\"under_five\"] = np.random.choice((0,1,2,3,4,5), size=150, p=(0.05, 0.35, 0.25, 0.20, 0.10, 0.05))\n",
    "full_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We now will calibrate the nonreponse weight (*nr_weight*) to ensure that the estimated number of households in poverty is equal to 4,700 and the estimated total number of children under five is 30,8500. The control numbers 4,700 and 30,800 are obtained from the table above. \n",
    "\n",
    "The class *SampleWeight()* uses the method *calibrate(samp_weight, aux_vars, control, domain, scale, bounded, additive)* to adjust the weight using the GREG approach. \n",
    "* The contol values must be stored in a python dictionnary i.e. totals = {\"poverty\": 4700, \"under_five\": 30800}. In this case, we have two numerical variables poverty with values in {0, 1} and under_five with values in {0, 1, 2, 3, 4, 5}. \n",
    "* *X* is the matrix of covariates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = {\"poverty\": 4700, \"under_five\": 30800}\n",
    "\n",
    "full_sample[\"calib_weight\"] = SampleWeight().calibrate(\n",
    "    full_sample[\"nr_weight\"], full_sample[[\"poverty\", \"under_five\"]], totals\n",
    "    )\n",
    "\n",
    "full_sample[[\"cluster\", \"region\", \"household\", \"nr_weight\", \"calib_weight\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can confirm that the estimated totals for the auxiliary variables are equal to their control values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty = full_sample[\"poverty\"]\n",
    "under_5 = full_sample[\"under_five\"]\n",
    "nr_weight = full_sample[\"nr_weight\"]\n",
    "calib_weight = full_sample[\"calib_weight\"]\n",
    "\n",
    "print(f\"Total estimated number of poor households was {sum(poverty*nr_weight):.2f} before and {sum(poverty*calib_weight):.2f} after adjustment \\n\")\n",
    "print(f\"Total estimated number of children under 5 was {sum(under_5*nr_weight):.2f} before and {sum(under_5*calib_weight):.2f} after adjustment \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If we want to control by domain then we can do so using the parameter *domain* of *calibrate()*. Firs we need to update the python dictionnary holding the control values. Now, those values have to be provided for each domain. Note that the dictionnary is now a nested dictionnary where the higher level keys hold the domain values i.e. East, North, South and West. Then the higher level values of the dictionnary are the dictionnaries providing mapping for the auxiliary variables and the corresponding control values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_by_domain = {\n",
    "    \"East\": {\"poverty\": 1200, \"under_five\": 6300}, \n",
    "    \"North\": {\"poverty\": 200, \"under_five\": 4000}, \n",
    "    \"South\": {\"poverty\": 1100, \"under_five\": 6500}, \n",
    "    \"West\": {\"poverty\": 2200, \"under_five\": 14000}\n",
    "    }\n",
    "\n",
    "full_sample[\"calib_weight_d\"] = SampleWeight().calibrate(\n",
    "    full_sample[\"nr_weight\"], full_sample[[\"poverty\", \"under_five\"]], totals_by_domain, full_sample[\"region\"]\n",
    "    )\n",
    "\n",
    "full_sample[[\"cluster\", \"region\", \"household\", \"nr_weight\", \"calib_weight\", \"calib_weight_d\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Note that the GREG domain estimates above do not have the additive property. That is the GREG domain estimates do not sum to the overal GREG estimate. To see this, let's assume that we want to estimate the number of households. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The number of households using the overall GREG is: {sum(full_sample['calib_weight']):.2f} \\n\")\n",
    "print(f\"The number of households using the domain GREG is: {sum(full_sample['calib_weight_d']):.2f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can force the adittive property by setting the additive flag to true as shown below, by default the flag is set to false. However, with the additive property, a set of adjusted sample weight is created for each domain. Hence, four sets of adjusted sample weights will be created for our example. The output is no longer a vector but a matrix with four columns. To estimate a given domain, the user will have to use the associated column of matrix. \n",
    "\n",
    "**Important**\n",
    "* Note that GREG can produce negative weights. Future version of the library will implement optional modifications to address negative or large weights. \n",
    "* Also, note that units outside of the domain of interest have non-zero sampling weights. This is necessary to achieve the additive property. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_weight_d2 = SampleWeight().calibrate(\n",
    "    full_sample[\"nr_weight\"], full_sample[[\"poverty\", \"under_five\"]], totals_by_domain, full_sample[\"region\"], additive=True\n",
    "    )\n",
    "\n",
    "calib_weight_d2 = pd.DataFrame(calib_weight_d2, columns=[\"East\", \"North\", \"South\", \"West\"])\n",
    "calib_weight_d2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The GREG domain estimates for the number of households are:\\n{calib_weight_d2.sum()} \\n\")\n",
    "\n",
    "print(f\"The sum of the GREG domain estimates (with the additive property) for the number of households are: {sum(calib_weight_d2.sum()):.2f} which is the same as the overall GREG estimate previously calculed as {sum(full_sample['calib_weight']):.2f}. In summary:\\n\")\n",
    "\n",
    "print(f\"The number of households using the overall GREG estimate is: {sum(full_sample['calib_weight']):.2f} \\n\")\n",
    "print(f\"The number of households using the domain GREG estimates is: {sum(full_sample['calib_weight_d']):.2f} - with ADDITIVE=FALSE \\n\")\n",
    "print(f\"The number of households using the domain GREG estimates is: {sum(calib_weight_d2.sum()):.2f} - with ADDITIVE=TRUE \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All the calibration auxiliary variables seen above are numerical but categorical variables may also be used. The approach used by the class method *calibrate()* is to trasform the categorical variables into dummy variables which are used to fit the associated regression model. The user have to provide the control values associated to the adjsutment cells. To facilitate this process, the user can take advantage of the method *calib_covariates(data, x_cat, x_cont, domain)*. This method take the auxiliary variables as input and return a matrix of the auxiliary variables and a dictionnary to be updated with the control values. These two output objects are inputs to *calibrate()*.\n",
    "\n",
    "Assume that we want to calibrate the weights based on the variables *education* (categorical) and *under_five* (numerical). We can use the snipet of code below to create the matrix of auxiliary variables and the dictionnary object to map adjsutment classes to control values. Note that the categorical variables are presented by value while the continuous variable has only one entry in the dictionnary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_vars, control_dict = SampleWeight().calib_covariates(full_sample, x_cat=[\"education\"], x_cont=[\"under_five\"])\n",
    "\n",
    "print(f\"The dictionnary for mapping domains to control values: {control_dict}\\n\")\n",
    "print(f\"A slice of the matrix of auxiliary variables:\\n{aux_vars[0:14,]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The control values are 30800 for under_five, 5950 for low education, 7300 for medium education, and 1450 for high education. Let's update *aux_dict* then run *calibrate()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dict[\"under_five\"] = 30800\n",
    "control_dict[\"Low\"] = 5950\n",
    "control_dict[\"Medium\"] = 7300\n",
    "control_dict[\"High\"] = 1450\n",
    "\n",
    "full_sample[\"calib_weight2\"] = SampleWeight().calibrate(full_sample[\"nr_weight\"], aux_vars, control_dict)\n",
    "\n",
    "full_sample[[\"cluster\", \"region\", \"household\", \"nr_weight\", \"calib_weight2\"]].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_vars, control_dict = SampleWeight().calib_covariates(full_sample, x_cat=[\"education\"], x_cont=[\"under_five\"], domain=\"region\")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(control_dict)\n",
    "print(f\"\\nA slice of the matrix of auxiliary variables:\\n{aux_vars[0:14,]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dict[\"East\"][\"under_five\"] = 6300\n",
    "control_dict[\"East\"][\"Low\"] = 2000\n",
    "control_dict[\"East\"][\"Medium\"] = 1400\n",
    "control_dict[\"East\"][\"High\"] = 350\n",
    "\n",
    "control_dict[\"North\"][\"under_five\"] = 4000\n",
    "control_dict[\"North\"][\"Low\"] = 550\n",
    "control_dict[\"North\"][\"Medium\"] = 700\n",
    "control_dict[\"North\"][\"High\"] = 250\n",
    "\n",
    "control_dict[\"South\"][\"under_five\"] = 6500\n",
    "control_dict[\"South\"][\"Low\"] = 1300\n",
    "control_dict[\"South\"][\"Medium\"] = 1200\n",
    "control_dict[\"South\"][\"High\"] = 350\n",
    "\n",
    "control_dict[\"West\"][\"under_five\"] = 14000\n",
    "control_dict[\"West\"][\"Low\"] = 2100\n",
    "control_dict[\"West\"][\"Medium\"] = 4000\n",
    "control_dict[\"West\"][\"High\"] = 500\n",
    "\n",
    "full_sample[\"calib_weight3\"] = SampleWeight().calibrate(full_sample[\"nr_weight\"], aux_vars, control_dict, full_sample[\"region\"])\n",
    "\n",
    "full_sample[[\"cluster\", \"region\", \"household\", \"education\", \"under_five\", \"nr_weight\", \"calib_weight3\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalization <a name=\"section4\"></a>\n",
    "\n",
    "Sometimes surveys adjust their sample weights to sum to arbitrary constants. This is known as normalizing sample weights. Sample weights normalization is less common modern surveys. However, DHS and MICS still normalize their final sample weights to sum to the sample size. Note that estimates of totals are not meaning using normalized weights but relative estimates such as mean, proportion or ratio remains valid as the normalization constant cancel out. \n",
    "\n",
    "We can use the class method *normalize(samp_weight, control, domain)* to adjust sample weights to sum to some constant across the sample or by normalization domain. Users should be careful when normalizing by domain as it will change the distribution of the weights across normalization domains. *normalize()* implementes the domain parameter for compleness and flexibility but it be shaldom used in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sample[\"norm_weight\"] = SampleWeight().normalize(full_sample[\"nr_weight\"])\n",
    "\n",
    "\n",
    "full_sample[[\"cluster\", \"region\", \"nr_weight\", \"norm_weight\"]].head(25)\n",
    "\n",
    "print((full_sample.shape[0], full_sample[\"norm_weight\"].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "When *normalize()* is called with only the parameter *samp_weight* then the sample weights are normalized to sum to the length of the sample weight vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sample[\"norm_weight2\"] = SampleWeight().normalize(full_sample[\"nr_weight\"], control=300)\n",
    "\n",
    "print(f\"{full_sample['norm_weight2'].sum():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sample[\"norm_weight3\"] = SampleWeight().normalize(full_sample[\"nr_weight\"], domain=full_sample[\"region\"])\n",
    "\n",
    "weight_sum = full_sample.groupby([\"region\"]).sum()\n",
    "weight_sum.reset_index(inplace=True)\n",
    "weight_sum[[\"region\", \"nr_weight\", \"norm_weight\", \"norm_weight3\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As for the other methods, the control values by domain are provided using a python dictionnary that maps the domain to the associated normalization level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_level = {\"East\": 10, \"North\": 20, \"South\": 30, \"West\": 50}\n",
    "\n",
    "full_sample[\"norm_weight4\"] = SampleWeight().normalize(full_sample[\"nr_weight\"], norm_level, full_sample[\"region\"])\n",
    "\n",
    "weight_sum = full_sample.groupby([\"region\"]).sum()\n",
    "weight_sum.reset_index(inplace=True)\n",
    "weight_sum[[\"region\", \"nr_weight\", \"norm_weight\", \"norm_weight2\", \"norm_weight3\", \"norm_weight4\",]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python37464bitvenvvenv5c6ef32391d0424f8c980df2e3730c26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}